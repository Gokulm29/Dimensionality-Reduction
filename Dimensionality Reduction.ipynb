{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/P0slLXu/PCnUqXdGr474"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"kALIM4EzEGgW","executionInfo":{"status":"ok","timestamp":1736583179717,"user_tz":-330,"elapsed":2118,"user":{"displayName":"GOKUL M 717822I213","userId":"02929682022163025753"}}},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import zipfile\n","import io\n","import pandas as pd\n","from sklearn.cluster import KMeans\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score, classification_report\n","import numpy as np\n","import time\n","\n","# Function to download and load dataset\n","def load_data():\n","    page_url = 'https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones'\n","    page_response = requests.get(page_url)\n","    if page_response.status_code == 200:\n","        soup = BeautifulSoup(page_response.content, 'html.parser')\n","        download_link = soup.select_one('a[href$=\".zip\"]')['href']\n","        full_download_url = 'https://archive.ics.uci.edu' + download_link\n","        response = requests.get(full_download_url)\n","        if response.status_code == 200:\n","            with zipfile.ZipFile(io.BytesIO(response.content)) as outer_zip:\n","                inner_zip_name = 'UCI HAR Dataset.zip'\n","                with outer_zip.open(inner_zip_name) as inner_zip_file:\n","                    with zipfile.ZipFile(io.BytesIO(inner_zip_file.read())) as inner_zip:\n","                        with inner_zip.open('UCI HAR Dataset/train/X_train.txt') as myfile:\n","                            df = pd.read_csv(myfile, delim_whitespace=True, header=None)\n","                        with inner_zip.open('UCI HAR Dataset/train/y_train.txt') as myfile_y:\n","                            y = pd.read_csv(myfile_y, delim_whitespace=True, header=None)\n","    else:\n","        raise Exception(\"Failed to download or parse the dataset.\")\n","    return df, y"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score\n","from sklearn.cluster import KMeans\n","import numpy as np\n","import time\n","# Load dataset\n","df, y = load_data()\n","#TASK 1 - DO EDA and understand a little about the data.\n","#Only important thing is to know that it has a lot of features that don't make sense, just a\n","#bunch of readings from sensors.\n","#We think many of these features are redundant or irrelevant, and we want to find good features.\n","print(\"df\",df.head())\n","print()\n","print(\"data type\",df.dtypes)\n","print()\n","print(\"Shape\",df.shape)\n","print()\n","print(\"Null values\",df.isnull().sum())\n","print()\n","print(\"discribe the data\",df.describe())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUOq-WWJEIXZ","executionInfo":{"status":"ok","timestamp":1736583188747,"user_tz":-330,"elapsed":7119,"user":{"displayName":"GOKUL M 717822I213","userId":"02929682022163025753"}},"outputId":"1e1fe486-a4f0-4278-c2f7-d885c31f55ab"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-836ccc4d8ebc>:30: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n","  df = pd.read_csv(myfile, delim_whitespace=True, header=None)\n","<ipython-input-2-836ccc4d8ebc>:32: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n","  y = pd.read_csv(myfile_y, delim_whitespace=True, header=None)\n"]},{"output_type":"stream","name":"stdout","text":["df         0         1         2         3         4         5         6    \\\n","0  0.288585 -0.020294 -0.132905 -0.995279 -0.983111 -0.913526 -0.995112   \n","1  0.278419 -0.016411 -0.123520 -0.998245 -0.975300 -0.960322 -0.998807   \n","2  0.279653 -0.019467 -0.113462 -0.995380 -0.967187 -0.978944 -0.996520   \n","3  0.279174 -0.026201 -0.123283 -0.996091 -0.983403 -0.990675 -0.997099   \n","4  0.276629 -0.016570 -0.115362 -0.998139 -0.980817 -0.990482 -0.998321   \n","\n","        7         8         9    ...       551       552       553       554  \\\n","0 -0.983185 -0.923527 -0.934724  ... -0.074323 -0.298676 -0.710304 -0.112754   \n","1 -0.974914 -0.957686 -0.943068  ...  0.158075 -0.595051 -0.861499  0.053477   \n","2 -0.963668 -0.977469 -0.938692  ...  0.414503 -0.390748 -0.760104 -0.118559   \n","3 -0.982750 -0.989302 -0.938692  ...  0.404573 -0.117290 -0.482845 -0.036788   \n","4 -0.979672 -0.990441 -0.942469  ...  0.087753 -0.351471 -0.699205  0.123320   \n","\n","        555       556       557       558       559       560  \n","0  0.030400 -0.464761 -0.018446 -0.841247  0.179941 -0.058627  \n","1 -0.007435 -0.732626  0.703511 -0.844788  0.180289 -0.054317  \n","2  0.177899  0.100699  0.808529 -0.848933  0.180637 -0.049118  \n","3 -0.012892  0.640011 -0.485366 -0.848649  0.181935 -0.047663  \n","4  0.122542  0.693578 -0.615971 -0.847865  0.185151 -0.043892  \n","\n","[5 rows x 561 columns]\n","\n","data type 0      float64\n","1      float64\n","2      float64\n","3      float64\n","4      float64\n","        ...   \n","556    float64\n","557    float64\n","558    float64\n","559    float64\n","560    float64\n","Length: 561, dtype: object\n","\n","Shape (7352, 561)\n","\n","Null values 0      0\n","1      0\n","2      0\n","3      0\n","4      0\n","      ..\n","556    0\n","557    0\n","558    0\n","559    0\n","560    0\n","Length: 561, dtype: int64\n","\n","discribe the data                0            1            2            3            4    \\\n","count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000   \n","mean      0.274488    -0.017695    -0.109141    -0.605438    -0.510938   \n","std       0.070261     0.040811     0.056635     0.448734     0.502645   \n","min      -1.000000    -1.000000    -1.000000    -1.000000    -0.999873   \n","25%       0.262975    -0.024863    -0.120993    -0.992754    -0.978129   \n","50%       0.277193    -0.017219    -0.108676    -0.946196    -0.851897   \n","75%       0.288461    -0.010783    -0.097794    -0.242813    -0.034231   \n","max       1.000000     1.000000     1.000000     1.000000     0.916238   \n","\n","               5            6            7            8            9    ...  \\\n","count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000  ...   \n","mean     -0.604754    -0.630512    -0.526907    -0.606150    -0.468604  ...   \n","std       0.418687     0.424073     0.485942     0.414122     0.544547  ...   \n","min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  ...   \n","25%      -0.980233    -0.993591    -0.978162    -0.980251    -0.936219  ...   \n","50%      -0.859365    -0.950709    -0.857328    -0.857143    -0.881637  ...   \n","75%      -0.262415    -0.292680    -0.066701    -0.265671    -0.017129  ...   \n","max       1.000000     1.000000     0.967664     1.000000     1.000000  ...   \n","\n","               551          552          553          554          555  \\\n","count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000   \n","mean      0.125293    -0.307009    -0.625294     0.008684     0.002186   \n","std       0.250994     0.321011     0.307584     0.336787     0.448306   \n","min      -1.000000    -0.995357    -0.999765    -0.976580    -1.000000   \n","25%      -0.023692    -0.542602    -0.845573    -0.121527    -0.289549   \n","50%       0.134000    -0.343685    -0.711692     0.009509     0.008943   \n","75%       0.289096    -0.126979    -0.503878     0.150865     0.292861   \n","max       0.946700     0.989538     0.956845     1.000000     1.000000   \n","\n","               556          557          558          559          560  \n","count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000  \n","mean      0.008726    -0.005981    -0.489547     0.058593    -0.056515  \n","std       0.608303     0.477975     0.511807     0.297480     0.279122  \n","min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  \n","25%      -0.482273    -0.376341    -0.812065    -0.017885    -0.143414  \n","50%       0.008735    -0.000368    -0.709417     0.182071     0.003181  \n","75%       0.506187     0.359368    -0.509079     0.248353     0.107659  \n","max       0.998702     0.996078     1.000000     0.478157     1.000000  \n","\n","[8 rows x 561 columns]\n"]}]},{"cell_type":"code","source":["y.values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xMoCJb_xKuSY","executionInfo":{"status":"ok","timestamp":1736583189586,"user_tz":-330,"elapsed":4,"user":{"displayName":"GOKUL M 717822I213","userId":"02929682022163025753"}},"outputId":"4a227d8c-bac1-4be3-dee0-a166737cdac7"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5],\n","       [5],\n","       [5],\n","       ...,\n","       [2],\n","       [2],\n","       [2]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# Task 2: Encode class labels\n","# YOUR CODE HERE: Use LabelEncoder to encode class labels\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","encode_y = le.fit_transform(y.values.ravel())\n","print(encode_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UJsUUFDmI16V","executionInfo":{"status":"ok","timestamp":1736583191687,"user_tz":-330,"elapsed":5,"user":{"displayName":"GOKUL M 717822I213","userId":"02929682022163025753"}},"outputId":"b54b4b2c-8138-4bda-c1b8-47901abeae49"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[4 4 4 ... 1 1 1]\n"]}]},{"cell_type":"code","source":["# Task 3: Scale the features using StandardScaler\n","# YOUR CODE HERE: Apply StandardScaler to df\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaled_df = scaler.fit_transform(df)\n","print(scaled_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SL2qOqPtJlt8","executionInfo":{"status":"ok","timestamp":1736583281377,"user_tz":-330,"elapsed":447,"user":{"displayName":"GOKUL M 717822I213","userId":"02929682022163025753"}},"outputId":"d8349f1b-fb1e-4a06-b3da-f270a259602e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.20064157 -0.0636826  -0.41962845 ... -0.68721921  0.40794614\n","  -0.00756789]\n"," [ 0.05594788  0.03148567 -0.25390836 ... -0.694138    0.40911698\n","   0.00787517]\n"," [ 0.07351535 -0.04341648 -0.07629468 ... -0.702239    0.4102883\n","   0.02650234]\n"," ...\n"," [-0.01566765  0.0167814   1.13222107 ... -0.56584847  0.64059683\n","   0.34870928]\n"," [ 0.21586648 -0.02812252 -0.86770988 ... -0.57766781  0.63147758\n","   0.29327564]\n"," [ 1.09620157  0.12919873 -1.67268082 ... -0.57392691  0.63274259\n","   0.33396081]]\n"]}]},{"cell_type":"code","source":["# Task 4: Split the data into training and testing sets\n","# YOUR CODE HERE: Use train_test_split to split the data\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(scaled_df, encode_y, test_size=0.2, random_state=1)"],"metadata":{"id":"13sdrEHRbJ7w","executionInfo":{"status":"ok","timestamp":1736583678852,"user_tz":-330,"elapsed":394,"user":{"displayName":"GOKUL M 717822I213","userId":"02929682022163025753"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["##TASK 5 - 1. Create a pipeline using Gaussian Naive Bayes\n","#          2. Fit the model to the training data\n","#          3. Predict values for test set\n","#          4. Print accuracy score\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.naive_bayes import GaussianNB\n","import time\n","start_time = time.time()\n","pipeline = Pipeline([\n","    ('classifier', GaussianNB())\n","])\n","pipeline.fit(X_train, y_train)\n","y_pred = pipeline.predict(X_test)\n","a_score = accuracy_score(y_test, y_pred)\n","print(\"Accuracy :\",a_score)\n","c_report = classification_report(y_test, y_pred)\n","print(\"Classification Report :\", c_report)\n","#TASK 6 - 1. Note the start time before defining the pipeline\n","#         2. Note the end time and report the difference as the time taken by the model training and inf\n","end_time = time.time()\n","time_taken = end_time - start_time\n","print(\"Time taken :\",time_taken)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ChGWVrqfdMjX","executionInfo":{"status":"ok","timestamp":1736588003588,"user_tz":-330,"elapsed":443,"user":{"displayName":"GOKUL M 717822I213","userId":"02929682022163025753"}},"outputId":"b559caaf-8263-4bac-8c58-efc607cb7ec0"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy : 0.7307953772943576\n","Classification Report :               precision    recall  f1-score   support\n","\n","           0       0.94      0.70      0.80       247\n","           1       0.69      0.91      0.78       230\n","           2       0.76      0.75      0.75       185\n","           3       0.52      0.65      0.58       254\n","           4       0.77      0.93      0.84       282\n","           5       0.91      0.46      0.61       273\n","\n","    accuracy                           0.73      1471\n","   macro avg       0.76      0.73      0.73      1471\n","weighted avg       0.77      0.73      0.73      1471\n","\n","Time taken : 0.08387064933776855\n"]}]},{"cell_type":"code","source":["# TASK 7 - K-Means for dimensionality reduction\n","n_clusters = 50\n","kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n","kmeans.fit(scaled_df.T)\n","selected_features_indices = [np.random.choice(np.where(kmeans.labels_ == i)[0]) for i in range(n_clusters)]\n","selected_features = scaled_df[:, selected_features_indices]\n","print(selected_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_D0uldvthCe3","executionInfo":{"status":"ok","timestamp":1736588288346,"user_tz":-330,"elapsed":9387,"user":{"displayName":"GOKUL M 717822I213","userId":"02929682022163025753"}},"outputId":"b8c9430a-81c7-4ad8-8c6f-e0e39c850de4"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.75070248 -0.8700415  -0.84576709 ... -0.71840922  0.83592584\n","  -0.7953587 ]\n"," [ 0.37823231 -0.91161272 -0.83736443 ...  0.24525519  1.5570466\n","   0.13061414]\n"," [-0.12889875 -0.92085432 -0.8268538  ... -0.67367648  2.34039882\n","   1.15233574]\n"," ...\n"," [-1.03813467  1.13049623  0.77398378 ...  0.4560065  -0.5444463\n","   0.27787672]\n"," [-1.02518343  1.13361745  0.55595075 ...  0.23656391 -1.61361693\n","  -0.44397761]\n"," [-0.46742019  1.03595673  1.14297738 ...  0.15363336 -2.16406282\n","  -0.73192085]]\n"]}]}]}